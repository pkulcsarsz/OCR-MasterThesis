{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MasterThesis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiV0hau8Bg7J"
      },
      "source": [
        "## Load the code and data from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d22bI6XA2Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffa98eb-778f-4c10-a1a7-afca63548316"
      },
      "source": [
        "! git clone https://github.com/pkulcsarsz/OCR-MasterThesis.git\n",
        "import os\n",
        "os.chdir('OCR-MasterThesis')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "#import tensorflow as tf\n",
        "#import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OCR-MasterThesis'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 17613 (delta 5), reused 13 (delta 3), pack-reused 17596\u001b[K\n",
            "Receiving objects: 100% (17613/17613), 531.11 MiB | 38.82 MiB/s, done.\n",
            "Resolving deltas: 100% (11601/11601), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_js9aTFCB5aJ"
      },
      "source": [
        "Import models, define basic variables, then load the model. If neccesay then train. Otherwise if the cache is turned on, and found on disk, load from cache."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWkdLqZLv66h"
      },
      "source": [
        "import models\n",
        "# Define basic variables\n",
        "num_classes = 36\n",
        "inputShape = (32, 32, 3)\n",
        "dataset = 'dataset3'\n",
        "useCache = True\n",
        "stepsPerEpoch = 50\n",
        "n_epochs = 80\n",
        "\n",
        "t_m_default = models.mLeNetDefault(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n",
        "t_m_default_f = models.mLeNetDefault_Features(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n",
        "t_m_default_f_d = models.mLeNetDefault_Features_Dense(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n",
        "t_m_enhanced = models.mLeNetEnhanced(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n",
        "t_m_enhanced_f = models.mLeNetEnhanced_Features(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n",
        "t_m_enhanced_f_d = models.mLeNetEnhanced_Features_Dense(inputShape, num_classes, steps_per_epoch = stepsPerEpoch, epochs = n_epochs, use_cache=useCache, dataset=dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}